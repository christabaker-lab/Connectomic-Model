# -*- coding: utf-8 -*-
"""Auditory_Connectome_Model_Brian2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JP7xZK3l1H8Fzl9onVoddnJbx1cfsGMm
"""

# package installment
# !pip3 install fafbseg
# !pip3 install pandas
# !pip3 install numpy
# !pip3 install flybrains
# !pip3 install caveclient
# !pip install brian2

import fafbseg
from fafbseg import flywire
from caveclient import CAVEclient
# import flybrains
import pickle

import os
import numpy as np
import pandas as pd
from tqdm import tqdm
from textwrap import dedent
from datetime import datetime, timedelta
from matplotlib import pyplot as plt

from brian2 import NeuronGroup, Synapses, PoissonInput, SpikeMonitor, Network, TimedArray, start_scope
from brian2 import mV, ms, Hz

pd.options.mode.chained_assignment = None  # default='warn'

client = CAVEclient()
client.auth.save_token(token="5be2f6e6cfe49c7c7ccc0c8e791a60be", overwrite=True)
# CAVEclient authorization, code from the documentation
client = CAVEclient()
client.auth.save_token(token="5be2f6e6cfe49c7c7ccc0c8e791a60be",overwrite=True)
# client.auth.save_token(token="cf5a53b7c589672a22207c9ec5bdea33",overwrite=True)

datastack_name = "flywire_fafb_production"
client = CAVEclient(datastack_name)

synapse_table = client.info.get_datastack_info()['synapse_table']
print(synapse_table)

## datetime and extension for filenames

date = datetime.today().strftime('%Y%m%d')
todays_date = date[2:]
date_30d_ago = (datetime.today() - timedelta(days=30)).strftime('%Y%m%d')[2:]

print(date_30d_ago)

"""# Filtering of Princeton ids

"""

princeton_aud_filtered = pd.read_csv('filtered_connections.csv')

# CSV loader
def process_ids():
    aud_neurons_csv = pd.read_csv('Auditory neurons Lockwood et al updated.csv')
    princeton_conns_csv = pd.read_csv('connections_princeton_no_threshold.csv')
    joa_neurons_csv = flywire.search_annotations('cell_type:JO-A', exact=True)
    joa_neurons_csv.to_csv('joa_annotations.csv')
    job_neurons_csv = flywire.search_annotations('cell_type:JO-B', exact=True)
    job_neurons_csv.to_csv('job_annotations.csv')
    joc_neurons_csv = flywire.search_annotations('cell_type:JO-C', exact=True)
    joc_neurons_csv.to_csv('joc_annotations.csv')
    jod_neurons_csv = flywire.search_annotations('cell_type:JO-D', exact=True)
    jod_neurons_csv.to_csv('jod_annotations.csv')
    joe_neurons_csv = flywire.search_annotations('cell_type:JO-E', exact=True)
    joe_neurons_csv.to_csv('joe_annotations.csv')
    jof_neurons_csv = flywire.search_annotations('cell_type:JO-F', exact=True)
    jof_neurons_csv.to_csv('jof_annotations.csv')
    jomz_neurons_csv = flywire.search_annotations('cell_type:JO-mz', exact=True)
    jomz_neurons_csv.to_csv('jomz_annotations.csv')

    aud_neurons_ids = aud_neurons_csv[['Codex June 2024', 'Neuron name (Lockwood et al)']]
    aud_neurons_ids.rename(columns={'Codex June 2024':'root_id', 'Neuron name (Lockwood et al)': 'label'}, inplace=True)
    joa_updated_ids = joa_neurons_csv[['root_id', 'cell_type', 'side']]
    joa_updated_ids['label'] = joa_updated_ids.apply(get_neuron_label, axis=1)
    joa_updated_ids = joa_updated_ids[['root_id', 'label']]
    job_updated_ids = job_neurons_csv[['root_id', 'cell_type', 'side']]
    job_updated_ids['label'] = job_updated_ids.apply(get_neuron_label, axis=1)
    job_updated_ids = job_updated_ids[['root_id', 'label']]
    joc_updated_ids = joc_neurons_csv[['root_id', 'cell_type', 'side']]
    joc_updated_ids['label'] = joc_updated_ids.apply(get_neuron_label, axis=1)
    joc_updated_ids = joc_updated_ids[['root_id', 'label']]
    jod_updated_ids = jod_neurons_csv[['root_id', 'cell_type', 'side']]
    jod_updated_ids['label'] = jod_updated_ids.apply(get_neuron_label, axis=1)
    jod_updated_ids = jod_updated_ids[['root_id', 'label']]
    joe_updated_ids = joe_neurons_csv[['root_id', 'cell_type', 'side']]
    joe_updated_ids['label'] = joe_updated_ids.apply(get_neuron_label, axis=1)
    joe_updated_ids = joe_updated_ids[['root_id', 'label']]
    jof_updated_ids = jof_neurons_csv[['root_id', 'cell_type', 'side']]
    jof_updated_ids['label'] = jof_updated_ids.apply(get_neuron_label, axis=1)
    jof_updated_ids = jof_updated_ids[['root_id', 'label']]
    jomz_updated_ids = jomz_neurons_csv[['root_id', 'cell_type', 'side']]
    jomz_updated_ids['label'] = jomz_updated_ids.apply(get_neuron_label, axis=1)
    jomz_updated_ids = jomz_updated_ids[['root_id', 'label']]
    concat_aud_ids = pd.concat([aud_neurons_ids, joa_updated_ids, job_updated_ids, joc_updated_ids, jod_updated_ids, joe_updated_ids, jof_updated_ids, jomz_updated_ids]) # 483 is the last non-JON id
    set_concat_aud_ids_og = concat_aud_ids.drop_duplicates(subset=['root_id'], keep='first')
    # root_id_set = set(set_concat_aud_ids_og['root_id'])

sorted_adj_matrix = pd.read_csv('sorted_named_heatmap_AUD_JONs.csv')

set_concat_aud_ids = pd.DataFrame()
set_concat_aud_ids['label'] = sorted_adj_matrix['label'][1:]
set_concat_aud_ids['root_id'] = sorted_adj_matrix.iloc[0,:-1].astype('object')[1:].to_list()
set_concat_aud_ids.reset_index(drop=True, inplace=True)

# set_concat_aud_ids.to_csv('aud_label_root_id.csv')

"""# Connectivity list creation with additional info

### This section creates a connectivity list and adds additional information such as indexing the complete auditory ids and mapping it to the filtered Princeton data. Also interprets the nt_type as excitatory or inhibitory (currently everything except ACH is inhibitory).

TODO: get classification of DA, SER
"""

id_idx_dict = {j:i for i,j in enumerate(set_concat_aud_ids['root_id'])}
idx_id_dict = {i:j for i,j in enumerate(set_concat_aud_ids['root_id'])}

neurons_ranges = dict()

neuron_groupings = ['A1','A2','B1','B2','GF','WED-VLP','WV-WV','AVLP_pr01','WED_pr01','GNG_pr01','AVLP_pr22','IPS/WED_pr01','AVLP_pr31','AVLP_pr32','SAD_pr02','AVLP_pr04','AVLP_pr12','AVLP_PVLP_pr01','AVLP_pr36','AVLP_pr18','AVLP_pr05','IPS_pr01','AVLP_pr11','WED_pr02','IPS_pr02','AVLP_pr23','PVLP_pr03','SAD_pr01','AVLP_pr35','vpoEN','vpoIN','pMN1','pMN2','pC2la','pC2lb','pC2lc','pC2ld','pC1d','pC1e','aPN3','aPN2','JO-A','JO-B','JO-C','JO-D','JO-E','JO-F','JO-mz']
neurons_ranges = dict()
for group in neuron_groupings:
    indices_l = set_concat_aud_ids.index[set_concat_aud_ids['label'].str.startswith(group) & set_concat_aud_ids['label'].str.contains('_L')].to_list()
    indices_r = set_concat_aud_ids.index[set_concat_aud_ids['label'].str.startswith(group) & set_concat_aud_ids['label'].str.contains('_R')].to_list()
    if indices_l:
        if f'{group}_L' not in neurons_ranges.keys():
            neurons_ranges[f'{group}_L'] = indices_l
        else:
            neurons_ranges[f'{group}_L'].append(indices_l)
    if indices_r:
        if f'{group}_R' not in neurons_ranges:
            neurons_ranges[f'{group}_R'] = indices_r
        else:
            neurons_ranges[f'{group}_R'].append(indices_r)
    if not indices_l and not indices_r:
        indices = set_concat_aud_ids.index[set_concat_aud_ids['label'].str.startswith(group)].to_list()
        if indices:
            if group not in neurons_ranges.keys():
                neurons_ranges[group] = indices
            else:
                neurons_ranges[group].append(indices)

# princeton_aud_filtered.to_csv('aud_filtered_princeton.csv')

princeton_aud_filtered.dropna(how='all', inplace=True)

princeton_aud_filtered['Excitatory'] = np.where(princeton_aud_filtered['nt_type'] == 'ACH', 1, -1)
princeton_aud_filtered['Signed_Connectivity'] = princeton_aud_filtered['Excitatory'] * princeton_aud_filtered['syn_count']
princeton_aud_filtered['Presynaptic_Index'] = princeton_aud_filtered['pre_pt_root_id'].map(id_idx_dict)
princeton_aud_filtered['Postsynaptic_Index'] = princeton_aud_filtered['post_pt_root_id'].map(id_idx_dict)

princeton_aud_filtered

"""# Model Creation

"""

import brian2
def sinusoidal_rate(t, base_rate, amplitude, frequency):
    return base_rate + amplitude * brian2.sin(2 * 3.1415 * frequency * t)

exc

start_scope()
exc = [ id_idx_dict[n] for n in joa_updated_ids['root_id'] ]
params = {
    # trials
    't_run'     : 500 * ms,              # duration of trial
    'n_run'     : 1,                     # number of runs

    # network constants
    # Kakaria and de Bivort 2017 https://doi.org/10.3389/fnbeh.2017.00008
    'v_0'       : -52 * mV,               # resting potential
    'v_rst'     : -52 * mV,               # reset potential after spike
    'v_th'      : -45 * mV,               # threshold for spiking
    't_mbr'     :  20 * ms,               # membrane time scale (capacitance * resistance = .002 * uF * 10. * Mohm)

    # JÃ¼rgensen et al https://doi.org/10.1088/2634-4386/ac3ba6
    'tau'       : 5 * ms,                 # time constant

    # Lazar et al https://doi.org/10.7554/eLife.62362
    't_rfc'     : 2.2 * ms,               # refractory period

    # Paul et al 2015 doi: 10.3389/fncel.2015.00029
    't_dly'     : 1.8*ms,                 # delay for changes in post-synaptic neuron

    # Free parameter
    'w_syn'     : 1 * mV,              # weight per synapse (note: modulated by exponential decay)
    # Default activation rates
    'r_poi'     : 250*Hz,                 # default rate of the Poisson inputs
    'r_poi2'    :   0*Hz,                 # default rate of a 2nd class of Poisson inputs
    'f_poi'     : 150,                    # scaling factor for Poisson synapse; 250 is sufficient to cause spiking
    'A'         : 2.5*mV,
    'f'         : 10*Hz,

    # equations for neurons               # alpha synapse https://doi.org/10.1017/CBO9780511815706; See https://brian2.readthedocs.io/en/stable/user/converting_from_integrated_form.html
    'eqs'       : dedent('''
                    dv/dt = (v_0 - v + g) / t_mbr : volt (unless refractory)
                    dg/dt = -g / tau               : volt (unless refractory)
                    rfc                            : second
                    '''),
    # condition for spike
    'eq_th'     : 'v > v_th',
    # rules for spike
    'eq_rst'    : 'v = v_rst; w = 0; g = 0 * mV',


    'sine_frequency': 500*Hz,  # Frequency of the sine wave
    'sine_amplitude': 1*mV,   # Amplitude for exc neurons
}

neu = NeuronGroup( # create neurons
    N=len(set_concat_aud_ids),
    model=params['eqs'],
    method='linear',
    threshold=params['eq_th'],
    reset=params['eq_rst'],
    refractory='rfc',
    name='default_neurons',
    namespace=params,
)
neu.v = params['v_0'] # initialize values
neu.g = 0
neu.rfc = params['t_rfc']

# create synapses
syn = Synapses(neu, neu, 'w : volt', on_pre='g += w', delay=params['t_dly'], name='default_synapses')

# connect synapses
i_pre = princeton_aud_filtered['Presynaptic_Index'].values
i_post = princeton_aud_filtered['Postsynaptic_Index'].values
syn.connect(i=i_pre, j=i_post)

# define connection weight
syn.w = princeton_aud_filtered['Signed_Connectivity'].values * params['w_syn']

# object to record spikes
spk_mon = SpikeMonitor(neu)

pois = []
for i in exc:
    p = PoissonInput(
        target=neu[i],
        target_var='v',
        N=1,
        rate=params['r_poi'],
        weight=params['w_syn']*params['f_poi']
        )
    neu[i].rfc = 0 * ms # no refractory period for Poisson targets
    pois.append(p)

net = Network(neu, syn, spk_mon, *pois)
net.run(duration=params['t_run'])


# Plot the spike raster
fig, axs = plt.subplots(1, 1, figsize=(10, 6), sharex=True)

# Plot spikes for JON neurons
axs.scatter(spk_mon.t/ms, spk_mon.i, color='blue', s=2)
axs.set_ylabel('JON Neuron Index')
axs.set_title('Spiking Activity of 1st-Level JON Neurons')

# plt.tight_layout()
plt.show()

with open('id_idx_dict.pickle', 'wb') as fi1:
    pickle.dump(id_idx_dict, fi1, protocol=pickle.HIGHEST_PROTOCOL)

with open('idx_id_dict.pickle', 'wb') as fi2:
    pickle.dump(idx_id_dict, fi2, protocol=pickle.HIGHEST_PROTOCOL)

with open('neuron_ranges.pickle', 'wb') as fi3:
    pickle.dump(neurons_ranges, fi3, protocol=pickle.HIGHEST_PROTOCOL)

with open('neuron_groupings.pickle', 'wb') as fi4:
    pickle.dump(neuron_groupings, fi4, protocol=pickle.HIGHEST_PROTOCOL)

neurons_ranges

princeton_data = pd.read_csv('connections_princeton_no_threshold.csv')
aud_data = pd.read_csv('Auditory neurons Lockwood et al updated.csv')

princeton_data

aud_pre = princeton_data[(princeton_data['pre_pt_root_id'].isin(aud_data['Codex June 2024'])) & (princeton_data['syn_count'] > 5)]
aud_post = princeton_data[(princeton_data['post_pt_root_id'].isin(aud_data['Codex June 2024'])) & (princeton_data['syn_count'] > 5)]

aud_filtered = pd.concat([aud_pre, aud_post])[['pre_pt_root_id','syn_count']]

aud_filtered.groupby(['pre_pt_root_id']).sum()